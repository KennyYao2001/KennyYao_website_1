---
layout: archive
title: ""
permalink: /publications/
author_profile: true
---

<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <title>Your Name</title>
    <meta name="author" content="Your Name">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <!-- Header Content Here -->
      
      <tr>
        <td style="padding:20px;width:100%;vertical-align:middle">
          <h2>Research</h2>
          <p>
            I'm interested in computer vision, deep learning, generative AI, and image processing. Most of my research is about inferring the physical world (shape, motion, color, light, etc) from images, usually with radiance fields. Representative papers are <span class="highlight">highlighted</span>.
          </p>
        </td>
      </tr>

      <tr onmouseout="smerf_stop()" onmouseover="smerf_start()">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <div class="two" id='smerf_image'><video  width=100% muted autoplay loop>
          <source src="images/smerf.mp4" type="video/mp4">
          Your browser does not support the video tag.
          </video></div>
          <img src='images/smerf.jpg' width=100%>
        </div>
        <script type="text/javascript">
          function smerf_start() {
            document.getElementById('smerf_image').style.opacity = "1";
          }

          function smerf_stop() {
            document.getElementById('smerf_image').style.opacity = "0";
          }
          smerf_stop()
        </script>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://smerf-3d.github.io/">
          <span class="papertitle">SMERF: Streamable Memory Efficient Radiance Fields for Real-Time Large-Scene Exploration</span>
        </a>
        <br>
		<a href="http://www.stronglyconvex.com/about.html">Daniel Duckworth*</a>,
		<a href="https://phogzone.com/">Peter Hedman*</a>,
		<a href="https://creiser.github.io/">Christian Reiser</a>,
		<a href="">Peter Zhizhin</a>,
		<a href="">Jean-François Thibert</a>,
        <a href="https://lucic.ai/">Mario Lučić</a>,
        <a href="https://szeliski.org/">Richard Szeliski</a>,
		<strong>Jonathan T. Barron</strong>
        <br>
        <em>arXiv</em>, 2023
        <br>
        <a href="https://smerf-3d.github.io/">project page</a>
        /
        <a href="https://www.youtube.com/watch?v=zhO8iUBpnCc">video</a>
        /
        <a href="https://arxiv.org/abs/2312.07541">arXiv</a>
        <p></p>
        <p>
        Distilling a Zip-NeRF into a tiled set of MERFs lets you fly through radiance fields on laptops and smartphones at 60 FPS.
        </p>
      </td>
    </tr>
      
      
      <!-- Paper 1 Content -->
      <tr>
        <td style="padding:20px;width:100%;vertical-align:middle">
          <!-- Replace with your actual image source and paper details -->
          <div class="one">
            <img src='path_to_your_image_paper1.jpg' width=100%>
          </div>
          <a href="http://academicpages.github.io/files/paper2.pdf">
            <span class="papertitle">Transferring Foundation Models for Generalizable Robotic Manipulation</span>
          </a>
          <br>
          Yang, J., Tan, W., Jin, C., Yao, K., Liu, B., Fu, J., Song, R., & Wang, L.
          <br>
          <em>arXiv</em>, 2023
          <br>
          <a href="http://academicpages.github.io/files/paper2.pdf">paper url</a>
          /
          <a href="/2023-10-1-GraspAnything">permalink</a>
          /
          <a href="#">venue</a>
          <p></p>
          <p>
            Improving the generalization capabilities of general-purpose robotic manipulation agents in the real world...
          </p>
        </td>
      </tr>

      <!-- Paper 2 Content -->
      <tr>
        <td style="padding:20px;width:100%;vertical-align:middle">
          <!-- Replace with your actual image source and paper details -->
          <div class="one">
            <img src='path_to_your_image_paper2.jpg' width=100%>
          </div>
          <a href="http://academicpages.github.io/files/paper1.pdf">
            <span class="papertitle">Towards Subcentimeter Accuracy Digital-Twin Tracking via An RGBD-based Transformer Model and A Comprehensive Mobile Dataset</span>
          </a>
          <br>
          Huang, Z.*, Yao, K.*, Zhao, S. Z.*, Pan, C.*, Xu, T., Feng, W., & Yang, A. Y.
          <br>
          <em>arXiv</em>, 2023
          <br>
          <a href="http://academicpages.github.io/files/paper1.pdf">paper url</a>
          /
          <a href="/publication/2023-9-1-DTTD">permalink</a>
          /
          <a href="#">venue</a>
          <p></p>
          <p>
            The potential of digital-twin technology, involving the creation of precise digital replicas of physical objects, to reshape AR experiences...
          </p>
        </td>
      </tr>
      
    </tbody></table>
  </body>
</html>
