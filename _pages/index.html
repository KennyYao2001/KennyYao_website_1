---
layout: archive
title: ""
permalink: /publications/
author_profile: true
---

<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8">
    <title>Jon Barron</title>
    <meta name="author" content="Kenny Yao">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" href="stylesheet.css">
  </head>

  <body>
      <tr>
        <td>
          <h2>Research Interest:</h2>
          <p>
            I'm interested in computer vision, deep learning, generative AI, and robot learning. Representative papers are <span class="highlight">highlighted</span>.
          </p>
        </td>
      </tr>

<table style="width:100%; border:0; border-spacing:0; border-collapse:separate; margin:auto;">

  <tr bgcolor="#ffffd0" onmouseover="recon_start()" onmouseout="recon_stop()">
    <td style="padding:20px; vertical-align:middle;">
      <div class="one">
        <div class="two" id="recon_image">
          <video width="100%" height="100%" muted autoplay loop>
            <source src="images/recon.mp4" type="video/mp4">
            Your browser does not support the video tag.
          </video>
          <img src="images/recon.png" width="160">
        </div>
      </div>
    </td>
    <td style="padding:20px; vertical-align:middle;">
      <a href="https://arxiv.org/abs/2306.05716">
        <span class="papertitle">Transferring Foundation Models for Generalizable Robotic Manipulation</span>
      </a>
      <br>
      <br>
        <a href="https://www.cs.columbia.edu/~rundi/">Jiange Yang</a>,
	<a href="https://bmild.github.io/">Wenhui Tan</a>,
        <a href="https://henzler.github.io/">Chuhao Jin</a>,
	<strong>Keling Yao</strong>,
        <a href="https://poolio.github.io/">Bei Liu</a>,
        <a href="https://holynski.org/">Jianlong Fu/a>
	<a href="https://holynski.org/">Ruihua Song/a>
	<a href="https://holynski.org/">Gangshan Wu/a>
	<a href="https://holynski.org/">Limin Wang/a>
        <br>
      <em>arXiv</em>, 2024
      <br>
      <a href="https://reconfusion.github.io/">project page</a> /
      <a href="https://arxiv.org/abs/2306.05716">arXiv</a> /
      <a href="https://www.youtube.com/watch?v=1m9wNzfp_4E&t=1s">Video</a>
      <p>
        We propose a novel paradigm that effectively leverages language-reasoning segmentation mask generated by internet-scale foundation models, to condition robot manipulation tasks.
      </p>
    </td>
  </tr>

  <tr bgcolor="#ffffd0" onmouseover="recon_start()" onmouseout="recon_stop()">
    <td style="padding:20px; vertical-align:middle;">
      <div class="one">
        <div class="two" id="recon_image">
          <video width="100%" height="100%" muted autoplay loop>
            <source src="images/recon.mp4" type="video/mp4">
            Your browser does not support the video tag.
          </video>
          <img src="images/recon.png" width="160">
        </div>
      </div>
    </td>
    <td style="padding:20px; vertical-align:middle;">
      <a href="https://github.com/augcog/DTTD2">
        <span class="papertitle">Robust Digital-Twin Localization via An RGBD-based Transformer Network and A Comprehensive Evaluation on a Mobile Dataset</span>
      </a>
      <br>
      <br>Zixun Huang, Keling Yao, Seth Z. Zhao, Chuanyu Pan, Tianjian Xu, Weiyu Feng, Allen Y. Yang
        <a href="https://www.cs.columbia.edu/~rundi/">Zixun Huang*</a>,
	<strong>Keling Yao*</strong>,
        <a href="https://poolio.github.io/">Seth Z. Zhao*</a>,
        <a href="https://holynski.org/">Chuanyu Pan*/a>
	<a href="https://holynski.org/">Tianjian Xu/a>
	<a href="https://holynski.org/">Weiyu Feng/a>
	<a href="https://holynski.org/">Allen Y. Yang/a>
        <br>
      <em>arXiv</em>, 2024
      <br>
      <a href="https://github.com/augcog/DTTD2">project page</a> /
      <a href="https://arxiv.org/abs/2309.13570">arXiv</a> /
      <a href="https://youtu.be/QhYWyoPTmOk">Video</a>
      <p>
        We propose a transformer-based 6DoF pose estimator designed to achieve state-of-the-art accuracy under real-world noisy data. To systematically validate the new solution's performance against the prior art, we also introduce a novel RGBD dataset called Digital Twin Tracking Dataset v2 (DTTD2).
      </p>
    </td>
  </tr>

</table>


    <script>
      function recon_start() {
        document.getElementById('recon_image').style.opacity = "1";
      }
      function recon_stop() {
        document.getElementById('recon_image').style.opacity = "0";
      }
      recon_stop();
    </script>
  </body>
</html>
