---
layout: archive
title: ""
permalink: /publications/
author_profile: ture
---


<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Keling Yao</title>
  <meta name="author" content="Kenny Yao">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="icon" href="../images/favicon/favicon.ico" type="image/x-icon">
  <!-- Remove external stylesheet if not needed -->
  <!-- <link rel="stylesheet" href="stylesheet.css"> -->
  <style>
    
    /* Fonts definitions */
    @font-face {
      font-family: 'Lato';
      font-style: italic;
      font-weight: 400;
      src: local('Lato Italic'), local('Lato-Italic'), url(https://fonts.gstatic.com/s/lato/v15/S6u8w4BMUTPHjxsAUi-qNiXg7eU0.woff2) format('woff2');
      unicode-range: U+0100-024F, U+0259, U+1E00-1EFF, U+2020, U+20A0-20AB, U+20AD-20CF, U+2113, U+2C60-2C7F, U+A720-A7FF;
    }

    /* General styling */
    #keling-page body, td, th, tr, p, a {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 12px; /* Increased font size for better readability */
    }

    #keling-page h2 {
      margin: 0;
      font-weight: normal;
      font-size: 24px; /* Larger size for headings */
    }

    #keling-page .papertitle, strong {
      font-size: 14px; /* Larger size for titles and emphasized text */
    }

    #keling-page .name {
      padding-top: 20px;
      margin: 0;
      font-size: 34px; /* Larger size for names */
    }

    /* Link styling */
    #keling-page a {
      color: #1772d0;
      text-decoration: none;
    }

    #keling-page a:focus, a:hover {
      color: #f09228;
      text-decoration: underline; /* Added underline on hover for better accessibility */
    }

    /* Image container styling */
    #keling-page  .one, .two {
      width: 180px; /* Adjusted to fit larger images */
      height: 180px;
      position: relative;
    }

    #keling-page .two {
      position: absolute;
      transition: opacity .2s ease-in-out;
    }

    /* Highlighting */
    #keling-page span.highlight {
      background-color: #ffffd0;
    }

    /* No border styles for all tables */
     #keling-page table, th, td {
      border: none;
      border-collapse: collapse;
    }
  </style>
</head>
<body id="keling-page">
  <table style="width:100%; margin:auto;">
    <tr>
      <td>
        <!-- Research section -->
        <h2>Research Interest</h2>
        <p>I'm interested in computer vision, deep learning, large language models, and embodied AI.</p>

        <!-- Project entries -->
        <table style="width:100%; margin:auto;">
          <tr style="background-color:#ffffff;">
            <td style="padding:20px;">
              <div class="one">
                <img src="../images/MSRA.png" width="160">
              </div>
            </td>
            <td style="padding:20px;">
              <strong>Transferring Foundation Models for Generalizable Robotic Manipulation</strong>
              <br>
              Jiange Yang, Wenhui Tan, Chuhao Jin, <strong>Keling Yao</strong>, Bei Liu, Jianlong Fu, Ruihua Song, Gangshan Wu, Limin Wang
              <br>
              <em>arXiv</em>, 2024
              <br>
              <a href="https://arxiv.org/abs/2306.05716">arXiv</a> /
              <a href="https://www.youtube.com/watch?v=1m9wNzfp_4E&t=1s">Video</a>
              <p>
                We propose a novel paradigm that effectively leverages language-reasoning segmentation mask generated by internet-scale foundation models, to condition robot manipulation tasks.
              </p>
            </td>
          </tr>
          <tr style="background-color:#ffffff;">
            <td style="padding:20px;">
              <div class="one">
                <img src="../images/dttd2.png" width="160">
              </div>
            </td>
            <td style="padding:20px;">
              <strong>Robust Digital-Twin Localization via An RGBD-based Transformer Network and A Comprehensive Evaluation on a Mobile Dataset</strong>
              <br>
              Zixun Huang*, <strong>Keling Yao*</strong>, Seth Z. Zhao*, Chuanyu Pan*, Tianjian Xu, Weiyu Feng, Allen Y. Yang
              <br>
              <em>arXiv</em>, 2024
              <br>
              <a href="https://github.com/augcog/DTTD2">project page</a> /
              <a href="https://arxiv.org/abs/2309.13570">arXiv</a> /
              <a href="https://youtu.be/QhYWyoPTmOk">Video</a>
              <p>
                We propose a transformer-based 6DoF pose estimator designed to achieve state-of-the-art accuracy under real-world noisy data. To systematically validate the new solution's performance against the prior art, we also introduce a novel RGBD dataset called Digital Twin Tracking Dataset v2 (DTTD2).
              </p>
            </td>
          </tr>
        </table>
      </td>
    </tr>
  </table>
</body>
</html>
